{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab06_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmpU46TaGZUuUJ6hUjecGD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onegi95/TIL/blob/master/lab06_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "njfWYi2_0o_C"
      },
      "outputs": [],
      "source": [
        "x_data = [[1,2,1,1],\n",
        "          [2,1,3,2],\n",
        "          [3,1,3,4],\n",
        "          [4,1,5,5,],\n",
        "          [1,7,5,5],\n",
        "          [1,2,5,6],\n",
        "          [1,6,6,6],\n",
        "          [1,7,7,7]]\n",
        "\n",
        "y_data = [[0,0,1],\n",
        "          [0,0,1],\n",
        "          [0,0,1],\n",
        "          [0,1,0],\n",
        "          [0,1,0],\n",
        "          [0,1,0],\n",
        "          [1,0,0],\n",
        "          [1,0,0],]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# conver t into numpy and float format\n",
        "x_data = np.asarray(x_data, dtype=np.float32)\n",
        "y_data = np.asarray(y_data, dtype=np.float32)"
      ],
      "metadata": {
        "id": "WXK7hExi1Lnq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classes = 3 #num classes"
      ],
      "metadata": {
        "id": "wglIDNA31U-Q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "W = tf.Variable(tf.random.normal([4, nb_classes]), name='weight')\n",
        "b = tf.Variable(tf.random.normal([nb_classes]), name='bias')\n",
        "# logistic classifier\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hp12QF21bdx",
        "outputId": "71c98431-f907-4983-dc6b-9158da486238"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.5807766   2.098824   -2.3775187 ]\n",
            " [ 1.0915214  -0.7006056  -1.6607829 ]\n",
            " [ 3.249484   -2.031421   -0.41470528]\n",
            " [ 3.147521   -3.348388   -0.7863033 ]\n",
            " [ 7.8267665   6.1532426  -7.7148566 ]\n",
            " [ 7.3618684  -1.8233359  -1.7165753 ]\n",
            " [ 8.516856    3.8313057  -6.6004405 ]\n",
            " [ 9.981531    4.474295   -7.662692  ]], shape=(8, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[3.70666564e-01 6.22255266e-01 7.07811583e-03]\n",
            " [8.12752903e-01 1.35409057e-01 5.18379696e-02]\n",
            " [9.70202327e-01 4.93622012e-03 2.48613730e-02]\n",
            " [9.79356885e-01 1.47843990e-03 1.91647336e-02]\n",
            " [8.42045009e-01 1.57954901e-01 1.49862913e-07]\n",
            " [9.99783456e-01 1.02523241e-04 1.14074355e-04]\n",
            " [9.90856528e-01 9.14327893e-03 2.69558143e-07]\n",
            " [9.95959103e-01 4.04091133e-03 2.16497629e-08]], shape=(8, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax onehot test\n",
        "\n",
        "sample_db = [[8,2,1,4]]\n",
        "smaple_db = np.asarray(sample_db, dtype=np.float32)\n",
        "softmax = tf.nn.softmax([-1, 0., 1.])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4unQU8Zo2lVA",
        "outputId": "e495dff5-530d-4cf7-daba-f2e29336b009"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.09003057 0.24472848 0.66524094], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cost function : cross entropy\n",
        "\n",
        "# cross entropy cost/loss\n",
        "def cost_fn(X, Y):\n",
        "  logits = hypothesis = tf.nn.softmax(tf.matmul(X,W)+b)\n",
        "  cost = -tf.reduce_sum(Y*tf.math.log(logits), axis=1)\n",
        "  cost_mean = tf.reduce_mean(cost)\n",
        "  return cost_mean\n",
        "print(cost_fn(x_data, y_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRVBlHg726ol",
        "outputId": "adc792ad-fa3b-4218-f945-a4a1b98dc793"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.16325289, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_fn(X, Y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    cost = cost_fn(X, Y)\n",
        "    grads = tape.gradient(cost, [W,b]) # [W,b] = variables\n",
        "    return grads\n",
        "print(grad_fn(x_data, y_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjmHoVvu3lkj",
        "outputId": "e1bdb93e-07d6-4d6e-d400-e08646c68018"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[4.9507475e+00 2.9596324e+00 3.6944399e+00 6.5167680e+00 1.8454458e+00\n",
            " 9.1854210e+00 9.1855302e-03 4.0490832e-03], shape=(8,), dtype=float32)\n",
            "[<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
            "array([[ 1.3316064 , -0.61437035, -0.71723604],\n",
            "       [ 1.4142975 , -0.92807883, -0.48621857],\n",
            "       [ 2.467789  , -1.6344856 , -0.8333034 ],\n",
            "       [ 2.612443  , -1.7757818 , -0.8366612 ]], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.62020284, -0.25808492, -0.36211792], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(X, Y, epochs=2000, verbose=100):\n",
        "  optimizer = tf.optimizers.SGD(learning_rate=0.1)\n",
        "  for i in range(epochs):\n",
        "    grads = grad_fn(X, Y)\n",
        "    optimizer.apply_gradients(zip(grads, [W,b]))\n",
        "    if (i == 0) | ((i+1)%verbose==0):\n",
        "      print('Loss at epoch %d: %f' %(i+1, cost_fn(X,Y).numpy()))"
      ],
      "metadata": {
        "id": "7--L1QmI7lFs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(x_data, y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kreQ88LH8E7s",
        "outputId": "04b884b8-e7f6-422d-93fa-0e07e268bc3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epoch 1: 0.163193\n",
            "Loss at epoch 100: 0.157497\n",
            "Loss at epoch 200: 0.152118\n",
            "Loss at epoch 300: 0.147081\n",
            "Loss at epoch 400: 0.142354\n",
            "Loss at epoch 500: 0.137911\n",
            "Loss at epoch 600: 0.133727\n",
            "Loss at epoch 700: 0.129782\n",
            "Loss at epoch 800: 0.126055\n",
            "Loss at epoch 900: 0.122529\n",
            "Loss at epoch 1000: 0.119189\n",
            "Loss at epoch 1100: 0.116021\n",
            "Loss at epoch 1200: 0.113011\n",
            "Loss at epoch 1300: 0.110150\n",
            "Loss at epoch 1400: 0.107425\n",
            "Loss at epoch 1500: 0.104829\n",
            "Loss at epoch 1600: 0.102352\n",
            "Loss at epoch 1700: 0.099986\n",
            "Loss at epoch 1800: 0.097724\n",
            "Loss at epoch 1900: 0.095559\n",
            "Loss at epoch 2000: 0.093486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.nn.softmax(tf.matmul(x_data,W)+b) # hypothesis\n",
        "\n",
        "print(a)\n",
        "print(tf.argmax(a,1))\n",
        "print(tf.argmax(y_data, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33GYgCWg8gNr",
        "outputId": "3a5a3de0-a2b8-4a19-bf41-f4cebe49ffcd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[4.28412896e-08 1.52905763e-04 9.99847054e-01]\n",
            " [2.68331642e-04 4.72454242e-02 9.52486217e-01]\n",
            " [1.55243055e-10 9.75707844e-02 9.02429163e-01]\n",
            " [1.48567132e-08 9.11770821e-01 8.82291645e-02]\n",
            " [1.62209973e-01 8.30934942e-01 6.85506640e-03]\n",
            " [8.59201550e-02 9.14077699e-01 2.21895039e-06]\n",
            " [8.23345542e-01 1.76651359e-01 3.12498173e-06]\n",
            " [9.65990007e-01 3.40100117e-02 1.48562425e-08]], shape=(8, 3), dtype=float32)\n",
            "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n",
            "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n"
          ]
        }
      ]
    }
  ]
}